
# PEANUT

This repository is an official PyTorch implementation of the paper PEANUT: Fast Inference of Visual Autoregressive Model with Adjacency-Adaptive Dynamical Draft Trees.

All main code refers to the project [LANTERN](https://github.com/jadohu/LANTERN)

Thank the LANTERN team for their contributions to the open-source community

---

## ğŸ“° News

- **[2025-11-28] TODO: Change the eagle tree**
- **[2025-11-20] ğŸ‰ğŸ‰ğŸ‰ PEANUT is released! ğŸ‰ğŸ‰ğŸ‰**

---

## Performance

Below is a comparison of the effects of different methods

![Performance](data/picture/Performance.png)

---

## âš™ï¸ Installation

1. **Install Required Packages**
    **Requirements**
    - Python >= 3.10
    - PyTorch >= 2.4.0
    
    Install the dependencies listed in `requirements.txt`.
    ```bash
    git clone https://github.com/Haodong-Lei-Ray/PEANUT.git
    cd PEANUT
    conda create -n PEANUT python=3.10 -y
    conda activate PEANUT
    pip install -r requirements.txt
    ```

2. **Additional Setup**
    1. **Lumina-mGPT**
        For [Lumina-mGPT](https://github.com/Alpha-VLLM/Lumina-mGPT), we need to install `flash_attention` and `xllmx` packages.
        ```bash
        pip install flash-attn --no-build-isolation
        cd models/base_models/lumina_mgpt
        pip install -e .
        ```

3. **Checkpoints**
    All model weights and other required data should be stored in `ckpts/`.
    1. **Lumina-mGPT**
        For Lumina-mGPT, since currently the Chameleon implementation in transformers does not contain the VQ-VAE decoder, please manually download the original VQ-VAE weights [provided by Meta](https://github.com/facebookresearch/chameleon) and put them to the following directory:
        ```
        ckpts
        â””â”€â”€ lumina_mgpt
            â””â”€â”€ chameleon
                â””â”€â”€ tokenizer
                    â”œâ”€â”€ text_tokenizer.json
                    â”œâ”€â”€ vqgan.yaml
                    â””â”€â”€ vqgan.ckpt
        ```

        Also download the original model [`Lumina-mGPT-7B-768`](https://huggingface.co/Alpha-VLLM/Lumina-mGPT-7B-768) from Huggingface ğŸ¤— and put them to the following directory:
        ```
        ckpts
        â””â”€â”€ lumina_mgpt
            â””â”€â”€ Lumina-mGPT-7B-768
                â”œâ”€â”€ config.json
                â”œâ”€â”€ generation_config.json
                â”œâ”€â”€ model-00001-of-00002.safetensors
                â””â”€â”€ other files...
        ```
    2. **Anole**
        For Anole, download [`Anole-7b-v0.1-hf`](https://huggingface.co/leloy/Anole-7b-v0.1-hf), which is a huggingface style converted model from [`Anole`](https://huggingface.co/GAIR/Anole-7b-v0.1). 
        
        In addition, you should download the original VQ-VAE weights [provided by Meta](https://github.com/facebookresearch/chameleon) and put them to the following directory:

        ```
        ckpts
        â””â”€â”€ anole
            â”œâ”€â”€ Anole-7b-v0.1-hf
            |   â”œâ”€â”€ config.json
            |   â”œâ”€â”€ generation_config.json
            |   â”œâ”€â”€ model-00001-of-00003.safetensors
            |   â””â”€â”€ other files...
            â””â”€â”€ chameleon
                â””â”€â”€ tokenizer
                    â”œâ”€â”€ text_tokenizer.json
                    â”œâ”€â”€ vqgan.yaml
                    â””â”€â”€ vqgan.ckpt
        ```

        **(Optional) Trained drafter**
        To use trained drafter, you need to download [`anole_drafter`](https://huggingface.co/jadohu/anole_drafter) and save it under trained_drafters directory.
        ```
        ckpts
        â””â”€â”€ anole
            â””â”€â”€ trained_drafters
                â””â”€â”€ anole_drafter
                    â”œâ”€â”€ config.json
                    â”œâ”€â”€ generation_config.json
                    â”œâ”€â”€ pytorch_model.bin
                    â””â”€â”€ other files...
        ```

---

## âœ¨ Usage



## âš–ï¸ License

This project is distributed under the Chameleon License by Meta Platforms, Inc. For more information, please see the `LICENSE` file in the repository.

---

## ğŸ™ Acknowledgement
This repository is built with extensive reference to [FoundationVision/LlamaGen](https://github.com/FoundationVision/LlamaGen), [Alpha-VLLM/Lumina-mGPT](https://github.com/Alpha-VLLM/Lumina-mGPT) and [SafeAILab/EAGLE](https://github.com/SafeAILab/EAGLE), leveraging many of their core components and approaches.

<!-- ---

## ğŸ“„ Citation

```
@article{jang2024lantern,
  title={LANTERN: Accelerating Visual Autoregressive Models with Relaxed Speculative Decoding},
  author={Jang, Doohyuk and Park, Sihwan and Yang, June Yong and Jung, Yeonsung and Yun, Jihun and Kundu, Souvik and Kim, Sung-Yub and Yang, Eunho},
  journal={arXiv preprint arXiv:2410.03355},
  year={2024}
}
@article{park2025lanternenhancedrelaxedspeculative,
  title={LANTERN++: Enhanced Relaxed Speculative Decoding with Static Tree Drafting for Visual Auto-regressive Models}, 
  author={Sihwan Park and Doohyuk Jang and Sungyub Kim and Souvik Kundu and Eunho Yang},
  journal={arXiv preprint arXiv:2410.03355},
  year={2025}
}
``` -->